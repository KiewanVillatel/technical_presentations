{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install mlflow\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import random\n",
    "from hyperopt import hp, fmin, tpe, space_eval\n",
    "import mlflow.pyfunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment tracking with ML Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility and deployment.\n",
    "\n",
    "![ML flow](img/mlflow.png)\n",
    "![ML flow tracking](img/introduction-to-mlflow-11-638.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment or use existing one\n",
    "mlflow.set_experiment(experiment_name=\"simple_example\")\n",
    "\n",
    "# Start a ML flow experiment\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"Param1\", random.randint(0, 10))\n",
    "    mlflow.log_param(\"Param2\", random.randint(0, 10))\n",
    "    \n",
    "    # ... run your ML code ...\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"Metric1\", random.random())\n",
    "    mlflow.log_metric(\"Metric2\", random.random())\n",
    "    \n",
    "    # Log artifacts\n",
    "    sns_plot = sns.violinplot(x=\"x\", data=pd.DataFrame(columns=[\"x\"], data=np.random.randn(1000)))\n",
    "    fig = sns_plot.get_figure() \n",
    "    fig.savefig(\"fig.png\")\n",
    "    mlflow.log_artifact(\"fig.png\")\n",
    "    \n",
    "    # Log tag\n",
    "    mlflow.set_tag(\"user_name\", getpass.getuser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment can now be accessed with `mlflow ui` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment or use existing one\n",
    "mlflow.set_experiment(experiment_name=\"monitoring\")\n",
    "\n",
    "# Start a ML flow experiment\n",
    "with mlflow.start_run():\n",
    "    for i in range(60):\n",
    "        time.sleep(0.5)\n",
    "        mlflow.log_metric(key=\"metric\", \n",
    "                          value=random.random(), \n",
    "                          step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new experiment or use existing one\n",
    "mlflow.set_experiment(experiment_name=\"hyperopt\")\n",
    "\n",
    "# Loss function\n",
    "def loss(case, val):\n",
    "    return val if case == 'case 1' else val**2 \n",
    "\n",
    "# Wrap loss function to add mlflow loging\n",
    "def run_loss(args):\n",
    "    # Start a nested experiment\n",
    "    with mlflow.start_run(nested=True) as nested_run:      \n",
    "        case, val = args\n",
    "        \n",
    "        # Add tag\n",
    "        mlflow.set_tag(\"loss\", \"dummy\")\n",
    "        \n",
    "        # Log params\n",
    "        mlflow.log_param(\"case\", case)\n",
    "        mlflow.log_param(\"val\", val)\n",
    "\n",
    "        metric = loss(case=case, val=val)\n",
    "        \n",
    "        # Log metric\n",
    "        mlflow.log_metric(\"metric\", metric)\n",
    "        \n",
    "        return metric\n",
    "        \n",
    "# Define search space\n",
    "space = hp.choice('a',\n",
    "    [\n",
    "        ('case 1', 1 + hp.lognormal('c1', 0, 1)),\n",
    "        ('case 2', hp.uniform('c2', -10, 10))\n",
    "    ])\n",
    "        \n",
    "# Start ml flow run\n",
    "with mlflow.start_run() as run:   \n",
    "    best = fmin(run_loss, space, algo=tpe.suggest, max_evals=100)\n",
    "    \n",
    "    best_case, best_val = space_eval(space, best)\n",
    "    best_metric = loss(case=best_case, val=best_val)\n",
    "    \n",
    "    # Log params for best run\n",
    "    mlflow.log_param(\"case\", best_case)\n",
    "    mlflow.log_param(\"val\", best_val)\n",
    "    \n",
    "    # Log result for best run\n",
    "    mlflow.log_metric(\"metric\", best_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mlflow_project_model.py` script train a simple model and log it as an artifact. Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "python mlflow_project_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While runing a .py file, mlflow log the commit hash for free. This is convenient to reproduce experiments. Good practice: run from a clean directory! <br>\n",
    "Logged model contains also all information about dependencies versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the mlflow ui and retrieve trained model id\n",
    "run_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously trained model\n",
    "classifier = mlflow.pyfunc.load_model(model_uri=\"runs:/{}/model\".format(run_id))\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model serialization works with various ML frameworks (sklearn, tensorflow, keras ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat MLproject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a local project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mlflow run . -P max_iter=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a distant project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mlflow run https://github.com/KiewanVillatel/technical_presentations.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mlflow run https://github.com/KiewanVillatel/technical_presentations.git -v 3655ae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`experiment_tracking_tp/my_reproducible_experiment.py` contains simple code to train a MLP on the diabetes dataset. The goal is to instrument it with ML flow to get a fully reproducible experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python ./experiment_tracking_tp/my_reproducible_experiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you managed to create an experiment, log parameters, metrics and any relevant information, add a `conda.yaml` and `MLproject` file so that the experiment can be run with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mlflow run ./experiment_tracking_tp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other ideas:\n",
    "* add hyper-parameter tuning\n",
    "* modularize your code (see https://github.com/mlflow/mlflow/tree/master/examples/multistep_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going further\n",
    "* https://mlflow.org/\n",
    "* https://github.com/mlflow/mlflow/tree/master/examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
